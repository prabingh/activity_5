[
  {
    "objectID": "quarto.html",
    "href": "quarto.html",
    "title": "Séries temporelles et reproductibilité:Assignment 5",
    "section": "",
    "text": "Step 1 : Loading Libraries and data.\n\nThis code block loads required libraries for data manipulation (tidyverse), time series analysis (fpp3, forecast), data visualization (ggplot2).\nI then read the CO2 concentration data from a CSV file named “hawai.csv” using read_csv.\nFinally, the str function provides a summary of the data structure\n\n\n#Loading Libraries and data\nlibrary(tidyverse)\n\nWarning: package 'tidyverse' was built under R version 4.3.2\n\n\nWarning: package 'ggplot2' was built under R version 4.3.3\n\n\nWarning: package 'tibble' was built under R version 4.3.2\n\n\nWarning: package 'tidyr' was built under R version 4.3.3\n\n\nWarning: package 'readr' was built under R version 4.3.2\n\n\nWarning: package 'purrr' was built under R version 4.3.2\n\n\nWarning: package 'dplyr' was built under R version 4.3.2\n\n\nWarning: package 'stringr' was built under R version 4.3.2\n\n\nWarning: package 'forcats' was built under R version 4.3.2\n\n\nWarning: package 'lubridate' was built under R version 4.3.2\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.0     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(fpp3)\n\nWarning: package 'fpp3' was built under R version 4.3.3\n\n\n── Attaching packages ────────────────────────────────────────────── fpp3 0.5 ──\n✔ tsibble     1.1.4     ✔ fable       0.3.4\n✔ tsibbledata 0.4.1     ✔ fabletools  0.4.1\n✔ feasts      0.3.2     \n\n\nWarning: package 'tsibble' was built under R version 4.3.3\n\n\nWarning: package 'tsibbledata' was built under R version 4.3.3\n\n\nWarning: package 'feasts' was built under R version 4.3.3\n\n\nWarning: package 'fabletools' was built under R version 4.3.3\n\n\nWarning: package 'fable' was built under R version 4.3.3\n\n\n── Conflicts ───────────────────────────────────────────────── fpp3_conflicts ──\n✖ lubridate::date()    masks base::date()\n✖ dplyr::filter()      masks stats::filter()\n✖ tsibble::intersect() masks base::intersect()\n✖ tsibble::interval()  masks lubridate::interval()\n✖ dplyr::lag()         masks stats::lag()\n✖ tsibble::setdiff()   masks base::setdiff()\n✖ tsibble::union()     masks base::union()\n\nlibrary(forecast)\n\nWarning: package 'forecast' was built under R version 4.3.3\n\n\nRegistered S3 method overwritten by 'quantmod':\n  method            from\n  as.zoo.data.frame zoo \n\nlibrary(ggplot2)\n\n# Load the time series data from a CSV file\ntime_series_CO2 &lt;- read_csv(\"hawai.csv\")\n\nRows: 526 Columns: 2\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (2): time, CO2\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# Check the structure of the data\nstr(time_series_CO2)\n\nspc_tbl_ [526 × 2] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ time: num [1:526] 1958 1958 1958 1958 1958 ...\n $ CO2 : num [1:526] 316 317 317 317 316 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   time = col_double(),\n  ..   CO2 = col_double()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\n\nStep 2: Data Preparation.\n\nThis code block prepares the time series data for analysis.\nFirst, I convert the “time” column to a proper date format (YYYY.MM) using as.Date.\nThen, I create a time series object named my_time_series using the ts function. This function takes the CO2 concentration values, starting year (1958), starting month (January - denoted by 1), and frequency (monthly - specified as 12) as arguments.\n\n\n# Convert the \"time\" column to a Date format (YYYY.MM)\ntime_series_CO2$time &lt;- as.Date(paste0(time_series_CO2$time, \"-01\"), format = \"%Y.%m-%d\")\n\n# Create a time series object\nmy_time_series &lt;- ts(time_series_CO2$CO2, start = c(1958, 1), frequency = 12)\n\nStep 3: Train-Test Split.\n\nThis code block splits the data into training and testing sets for model development and evaluation.\nI calculate the split point (70% for training data) using the total data length.\nThe head function extracts the first 70% of data points as the training set (train).\nConversely, the tail function extracts the remaining 30% as the testing set (test).\nFinally, I verify that the splitting process is correct using the identical function.\n\n\n# Determine the split point for dividing data into training and testing sets\nsplit_point &lt;- round(0.7 * length(my_time_series))\n\n# Split the time series into training and testing sets\ntrain &lt;- head(my_time_series, split_point)\ntest &lt;- tail(my_time_series, length(my_time_series) - split_point)\n\n# Test that the splits are correct\nidentical(train, head(my_time_series, split_point))\n\n[1] TRUE\n\nidentical(test, tail(my_time_series, length(my_time_series) - split_point))\n\n[1] TRUE\n\n\nStep 4: ARIMA Model\n\nThis code block builds and applies an ARIMA model for CO2 concentration forecasting.\nFirst, I convert both training and testing data to a tsibble format using as_tsibble. This format is suitable for time series analysis with the fpp3 package.\nThe model function with the ARIMA argument fits an ARIMA model to the training data.\nI use the fitted model to generate forecasts for the testing set using the forecast function. The number of forecasts (h) is set to the length of the testing data.\nFinally, the autoplot function visualizes the actual CO2 concentration values against the forecasted values. The plot title and axis labels are specified using labs.\n\n\n# Convert data to tsibble format\ntrain &lt;- as_tsibble(train)\ntest &lt;- as_tsibble(test)\n\n# Fit an ARIMA model to the training data\narima_model &lt;- train %&gt;%\n  model(ARIMA = ARIMA(value))\n\n# Forecast using the ARIMA model\nforecast_values &lt;- arima_model %&gt;%\n  forecast(h = nrow(test))\n\n# Plot actual vs. forecasted values\nautoplot(forecast_values) +\n  labs(title = \"ARIMA Forecast\", x = \"Date\", y = \"CO2 Concentration\")\n\n\n\n\n\n\n\n\nInterpretation:\nThis graph shows a forecasted trend based on an ARIMA (Autoregressive Integrated Moving Average) model. ARIMA is a statistical method for analyzing and forecasting time series data. The label on the y-axis represents the CO2 concentration in ppm,while X-axis represent the date in years.The graph shows the increasing trend of CO2 concentration with date. The solid blue line represent the actual concentration.The area within a blue region is 80% confidence interval and area under purple region is within 95% confidence interval.\nStep 5: Residual analysis.alysis.\nThis code block calculates the residuals using test$value - forecast_values$.mean.\nThen, we create a data frame residual_df to facilitate residual visualization.\n\nA line plot of residuals over time is created using ggplot to observe patterns or trends in the residuals.\nThe Acf function generates an autocorrelation function (ACF) plot to assess any potential autocorrelation in the residuals.\nA Ljung-Box test is performed using Box.test to formally evaluate the randomness of residuals. Non-randomness in residuals can indicate model inadequacy.\nCalculating and Visualizing Residuals.\n\n# Calculate residuals\nresiduals &lt;- test$value - forecast_values$.mean\n\n# Create a data frame to visualize residuals\nresidual_df &lt;- data.frame(Time = time(residuals), Residuals = residuals)\n\n# Plot residuals over time\nggplot(residual_df, aes(x = Time, y = Residuals)) +\n  geom_line() +\n  labs(title = \"Residuals Plot\", x = \"Time\", y = \"Residuals\")\n\n\n\n\n\n\n\n# Plot autocorrelation function (ACF) of residuals\nAcf(residuals, main = \"ACF Plot of Residuals\")\n\n\n\n\n\n\n\n# Perform Ljung-Box test for residuals\nBox.test(residuals, lag = 20, type = \"Ljung-Box\")\n\n\n    Box-Ljung test\n\ndata:  residuals\nX-squared = 1237.3, df = 20, p-value &lt; 2.2e-16\n\n\n\nInterpretation:\nResiduals are the differences between the actual CO2 concentration values and the corresponding forecasted values from the ARIMA model.The positive value on the y axis signify the actual concentration was higher than the forecast,while negative values indicate the opposite.To get confirmation the Box-Ljung was performed, where data= residuals,X-squared= 1237.3,degree of freedom (df) =20 and p-value &lt;2.2e -16. A low p- value(less than significance level,typically 0.05) in Box-Ljung test indicates that we can reject the null hypothesis and conclude that the residual are not random. This implies the presence of autocorrelation in residual.\nResidual Distribution.\n\nTo visualize the distribution of residuals, we create a histogram plot using geom_histogram.\nA quantile-quantile (Q-Q) plot is generated using stat_qq to compare the distribution of residuals with a normal distribution.\nFinally, I perform a Shapiro-Wilk test for normality using shapiro.test to statistically assess whether the residuals are normally distributed. This assumption is often important for model accuracy and confidence interval validity.\n\n# Histogram of residuals\nhistogram_plot &lt;- ggplot(data.frame(Residuals = residuals), aes(x = Residuals)) +\n  geom_histogram(binwidth = 0.1, fill = \"skyblue\", color = \"black\") +\n  labs(title = \"Histogram of Residuals\", x = \"Residuals\", y = \"Frequency\") +\n  theme_minimal()\n\n# Q-Q plot of residuals\nqq_plot &lt;- ggplot(data.frame(Residuals = residuals), aes(sample = Residuals)) +\n  stat_qq() +\n  stat_qq_line(color = \"red\", linetype = \"dashed\") +\n  labs(title = \"Q-Q Plot of Residuals\") +\n  theme_minimal()\n\n# Display plots\nhistogram_plot\n\n\n\n\n\n\n\nqq_plot\n\n\n\n\n\n\n\n# Perform Shapiro-Wilk test for normality\nshapiro_test &lt;- residuals %&gt;%\n  stats::shapiro.test()\nshapiro_test\n\n\n    Shapiro-Wilk normality test\n\ndata:  .\nW = 0.93719, p-value = 1.893e-06\n\n\nInterpretation:\n\nA histogram is a graphical representation of the distribution of the data. In this case of ARIMA residuals,histogram of the residual is not bell shaped and this is more right skewed. similarly Shapiro wilk test provide the more accurate information on distribution of the data.In this case p-value=1.893 e-06 is extremely small so we can tentatively conclude that the residuals are not normally distributed. The W statistics of 0.93719 also suggest the deviation from normality.\nConclusions:\nThe extremely low p-value from the Ljung-Box test suggests that the ARIMA model fitted may not be reliable, as it indicates significant autocorrelation in the residuals. This implies that the model hasn’t adequately captured all the information in the data.\nTo improve this model:\nChoice of parameters for the ARIMA model experiment with different combinations of autoregressive (AR), differencing (I), and moving average (MA) terms to find a better-fitting model. This may involve trying different values for the order parameters (p, d, q) in the ARIMA model might be useful.\nIdentification and handling outliers or anomalies in the data appropriately. Outliers can significantly affect the model’s performance and may need to be treated or adjusted for before fitting the model.\nValidation of the model using alternative methods or datasets to ensure its robustness and generalizability. Cross-validation techniques or out-of-sample testing can help assess the model’s performance on unseen data."
  },
  {
    "objectID": "quarto.html#running-code",
    "href": "quarto.html#running-code",
    "title": "Séries temporelles et reproductibilité:Assignment 5",
    "section": "",
    "text": "Step 1 : Loading Libraries and data.\n\nThis code block loads required libraries for data manipulation (tidyverse), time series analysis (fpp3, forecast), data visualization (ggplot2).\nI then read the CO2 concentration data from a CSV file named “hawai.csv” using read_csv.\nFinally, the str function provides a summary of the data structure\n\n\n#Loading Libraries and data\nlibrary(tidyverse)\n\nWarning: package 'tidyverse' was built under R version 4.3.2\n\n\nWarning: package 'ggplot2' was built under R version 4.3.3\n\n\nWarning: package 'tibble' was built under R version 4.3.2\n\n\nWarning: package 'tidyr' was built under R version 4.3.3\n\n\nWarning: package 'readr' was built under R version 4.3.2\n\n\nWarning: package 'purrr' was built under R version 4.3.2\n\n\nWarning: package 'dplyr' was built under R version 4.3.2\n\n\nWarning: package 'stringr' was built under R version 4.3.2\n\n\nWarning: package 'forcats' was built under R version 4.3.2\n\n\nWarning: package 'lubridate' was built under R version 4.3.2\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.0     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(fpp3)\n\nWarning: package 'fpp3' was built under R version 4.3.3\n\n\n── Attaching packages ────────────────────────────────────────────── fpp3 0.5 ──\n✔ tsibble     1.1.4     ✔ fable       0.3.4\n✔ tsibbledata 0.4.1     ✔ fabletools  0.4.1\n✔ feasts      0.3.2     \n\n\nWarning: package 'tsibble' was built under R version 4.3.3\n\n\nWarning: package 'tsibbledata' was built under R version 4.3.3\n\n\nWarning: package 'feasts' was built under R version 4.3.3\n\n\nWarning: package 'fabletools' was built under R version 4.3.3\n\n\nWarning: package 'fable' was built under R version 4.3.3\n\n\n── Conflicts ───────────────────────────────────────────────── fpp3_conflicts ──\n✖ lubridate::date()    masks base::date()\n✖ dplyr::filter()      masks stats::filter()\n✖ tsibble::intersect() masks base::intersect()\n✖ tsibble::interval()  masks lubridate::interval()\n✖ dplyr::lag()         masks stats::lag()\n✖ tsibble::setdiff()   masks base::setdiff()\n✖ tsibble::union()     masks base::union()\n\nlibrary(forecast)\n\nWarning: package 'forecast' was built under R version 4.3.3\n\n\nRegistered S3 method overwritten by 'quantmod':\n  method            from\n  as.zoo.data.frame zoo \n\nlibrary(ggplot2)\n\n# Load the time series data from a CSV file\ntime_series_CO2 &lt;- read_csv(\"hawai.csv\")\n\nRows: 526 Columns: 2\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (2): time, CO2\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# Check the structure of the data\nstr(time_series_CO2)\n\nspc_tbl_ [526 × 2] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ time: num [1:526] 1958 1958 1958 1958 1958 ...\n $ CO2 : num [1:526] 316 317 317 317 316 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   time = col_double(),\n  ..   CO2 = col_double()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\n\nStep 2: Data Preparation.\n\nThis code block prepares the time series data for analysis.\nFirst, I convert the “time” column to a proper date format (YYYY.MM) using as.Date.\nThen, I create a time series object named my_time_series using the ts function. This function takes the CO2 concentration values, starting year (1958), starting month (January - denoted by 1), and frequency (monthly - specified as 12) as arguments.\n\n\n# Convert the \"time\" column to a Date format (YYYY.MM)\ntime_series_CO2$time &lt;- as.Date(paste0(time_series_CO2$time, \"-01\"), format = \"%Y.%m-%d\")\n\n# Create a time series object\nmy_time_series &lt;- ts(time_series_CO2$CO2, start = c(1958, 1), frequency = 12)\n\nStep 3: Train-Test Split.\n\nThis code block splits the data into training and testing sets for model development and evaluation.\nI calculate the split point (70% for training data) using the total data length.\nThe head function extracts the first 70% of data points as the training set (train).\nConversely, the tail function extracts the remaining 30% as the testing set (test).\nFinally, I verify that the splitting process is correct using the identical function.\n\n\n# Determine the split point for dividing data into training and testing sets\nsplit_point &lt;- round(0.7 * length(my_time_series))\n\n# Split the time series into training and testing sets\ntrain &lt;- head(my_time_series, split_point)\ntest &lt;- tail(my_time_series, length(my_time_series) - split_point)\n\n# Test that the splits are correct\nidentical(train, head(my_time_series, split_point))\n\n[1] TRUE\n\nidentical(test, tail(my_time_series, length(my_time_series) - split_point))\n\n[1] TRUE\n\n\nStep 4: ARIMA Model\n\nThis code block builds and applies an ARIMA model for CO2 concentration forecasting.\nFirst, I convert both training and testing data to a tsibble format using as_tsibble. This format is suitable for time series analysis with the fpp3 package.\nThe model function with the ARIMA argument fits an ARIMA model to the training data.\nI use the fitted model to generate forecasts for the testing set using the forecast function. The number of forecasts (h) is set to the length of the testing data.\nFinally, the autoplot function visualizes the actual CO2 concentration values against the forecasted values. The plot title and axis labels are specified using labs.\n\n\n# Convert data to tsibble format\ntrain &lt;- as_tsibble(train)\ntest &lt;- as_tsibble(test)\n\n# Fit an ARIMA model to the training data\narima_model &lt;- train %&gt;%\n  model(ARIMA = ARIMA(value))\n\n# Forecast using the ARIMA model\nforecast_values &lt;- arima_model %&gt;%\n  forecast(h = nrow(test))\n\n# Plot actual vs. forecasted values\nautoplot(forecast_values) +\n  labs(title = \"ARIMA Forecast\", x = \"Date\", y = \"CO2 Concentration\")\n\n\n\n\n\n\n\n\nInterpretation:\nThis graph shows a forecasted trend based on an ARIMA (Autoregressive Integrated Moving Average) model. ARIMA is a statistical method for analyzing and forecasting time series data. The label on the y-axis represents the CO2 concentration in ppm,while X-axis represent the date in years.The graph shows the increasing trend of CO2 concentration with date. The solid blue line represent the actual concentration.The area within a blue region is 80% confidence interval and area under purple region is within 95% confidence interval.\nStep 5: Residual analysis.alysis.\nThis code block calculates the residuals using test$value - forecast_values$.mean.\nThen, we create a data frame residual_df to facilitate residual visualization.\n\nA line plot of residuals over time is created using ggplot to observe patterns or trends in the residuals.\nThe Acf function generates an autocorrelation function (ACF) plot to assess any potential autocorrelation in the residuals.\nA Ljung-Box test is performed using Box.test to formally evaluate the randomness of residuals. Non-randomness in residuals can indicate model inadequacy.\nCalculating and Visualizing Residuals.\n\n# Calculate residuals\nresiduals &lt;- test$value - forecast_values$.mean\n\n# Create a data frame to visualize residuals\nresidual_df &lt;- data.frame(Time = time(residuals), Residuals = residuals)\n\n# Plot residuals over time\nggplot(residual_df, aes(x = Time, y = Residuals)) +\n  geom_line() +\n  labs(title = \"Residuals Plot\", x = \"Time\", y = \"Residuals\")\n\n\n\n\n\n\n\n# Plot autocorrelation function (ACF) of residuals\nAcf(residuals, main = \"ACF Plot of Residuals\")\n\n\n\n\n\n\n\n# Perform Ljung-Box test for residuals\nBox.test(residuals, lag = 20, type = \"Ljung-Box\")\n\n\n    Box-Ljung test\n\ndata:  residuals\nX-squared = 1237.3, df = 20, p-value &lt; 2.2e-16\n\n\n\nInterpretation:\nResiduals are the differences between the actual CO2 concentration values and the corresponding forecasted values from the ARIMA model.The positive value on the y axis signify the actual concentration was higher than the forecast,while negative values indicate the opposite.To get confirmation the Box-Ljung was performed, where data= residuals,X-squared= 1237.3,degree of freedom (df) =20 and p-value &lt;2.2e -16. A low p- value(less than significance level,typically 0.05) in Box-Ljung test indicates that we can reject the null hypothesis and conclude that the residual are not random. This implies the presence of autocorrelation in residual.\nResidual Distribution.\n\nTo visualize the distribution of residuals, we create a histogram plot using geom_histogram.\nA quantile-quantile (Q-Q) plot is generated using stat_qq to compare the distribution of residuals with a normal distribution.\nFinally, I perform a Shapiro-Wilk test for normality using shapiro.test to statistically assess whether the residuals are normally distributed. This assumption is often important for model accuracy and confidence interval validity.\n\n# Histogram of residuals\nhistogram_plot &lt;- ggplot(data.frame(Residuals = residuals), aes(x = Residuals)) +\n  geom_histogram(binwidth = 0.1, fill = \"skyblue\", color = \"black\") +\n  labs(title = \"Histogram of Residuals\", x = \"Residuals\", y = \"Frequency\") +\n  theme_minimal()\n\n# Q-Q plot of residuals\nqq_plot &lt;- ggplot(data.frame(Residuals = residuals), aes(sample = Residuals)) +\n  stat_qq() +\n  stat_qq_line(color = \"red\", linetype = \"dashed\") +\n  labs(title = \"Q-Q Plot of Residuals\") +\n  theme_minimal()\n\n# Display plots\nhistogram_plot\n\n\n\n\n\n\n\nqq_plot\n\n\n\n\n\n\n\n# Perform Shapiro-Wilk test for normality\nshapiro_test &lt;- residuals %&gt;%\n  stats::shapiro.test()\nshapiro_test\n\n\n    Shapiro-Wilk normality test\n\ndata:  .\nW = 0.93719, p-value = 1.893e-06\n\n\nInterpretation:\n\nA histogram is a graphical representation of the distribution of the data. In this case of ARIMA residuals,histogram of the residual is not bell shaped and this is more right skewed. similarly Shapiro wilk test provide the more accurate information on distribution of the data.In this case p-value=1.893 e-06 is extremely small so we can tentatively conclude that the residuals are not normally distributed. The W statistics of 0.93719 also suggest the deviation from normality.\nConclusions:\nThe extremely low p-value from the Ljung-Box test suggests that the ARIMA model fitted may not be reliable, as it indicates significant autocorrelation in the residuals. This implies that the model hasn’t adequately captured all the information in the data.\nTo improve this model:\nChoice of parameters for the ARIMA model experiment with different combinations of autoregressive (AR), differencing (I), and moving average (MA) terms to find a better-fitting model. This may involve trying different values for the order parameters (p, d, q) in the ARIMA model might be useful.\nIdentification and handling outliers or anomalies in the data appropriately. Outliers can significantly affect the model’s performance and may need to be treated or adjusted for before fitting the model.\nValidation of the model using alternative methods or datasets to ensure its robustness and generalizability. Cross-validation techniques or out-of-sample testing can help assess the model’s performance on unseen data."
  }
]